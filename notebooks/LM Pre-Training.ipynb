{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "\n",
    "from pytorch_pretrained_bert import (OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer,\n",
    "                                     OpenAIAdam, cached_path, WEIGHTS_NAME, CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.40244910553017"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'openai-gpt'\n",
    "special_tokens = ['_start_', '_delimiter_', '_classify_']\n",
    "gpt_tok = OpenAIGPTTokenizer.from_pretrained(model_name, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpt_tok.bpe_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tok.convert_tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCSTORIES_URL = \"https://s3.amazonaws.com/datasets.huggingface.co/ROCStories.tar.gz\"\n",
    "\n",
    "def load_rocstories_dataset(dataset_path):\n",
    "    \"\"\" Output a list of tuples(story, 1st continuation, 2nd continuation, label) \"\"\"\n",
    "    with open(dataset_path, encoding='utf_8') as f:\n",
    "        f = csv.reader(f)\n",
    "        output = []\n",
    "        next(f) # skip the first line\n",
    "        for line in tqdm(f):\n",
    "            output.append((' '.join(line[1:5]), line[5], line[6], int(line[-1])-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(obj):\n",
    "    \"\"\" Tokenize and encode a nested object \"\"\"\n",
    "    if isinstance(obj, str):\n",
    "        return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
    "    elif isinstance(obj, int):\n",
    "        return obj\n",
    "    return list(tokenize_and_encode(o) for o in obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_stories = cached_path(ROCSTORIES_URL)\n",
    "print(roc_stories)\n",
    "train_dataset = load_rocstories_dataset(roc_stories + '/cloze_test_val__spring201/cloze_test_ALL_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still trying to figure out Attention class from TF docs\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Permute\n",
    "from keras.layers import Layer\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# class BahdanauAttention(K.tf.keras.Model):\n",
    "class BahdanauAttention(Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units, name=\"W1_mat\")\n",
    "        self.W2 = Dense(units, name=\"W2_mat\")\n",
    "        self.V = Dense(1, name=\"V_mat\")\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = K.expand_dims(query, 1) # originally `tf.expand_dims`\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(K.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = K.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = K.tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Embedding, Bidirectional, Input\n",
    "from keras.models import Model\n",
    "\n",
    "in_layer = Input(shape=(None,))\n",
    "embedding = Embedding(input_dim=20000, output_dim=128)(in_layer)\n",
    "gru_out = GRU(units=128, return_sequences=True, return_state=True)(embedding)\n",
    "\n",
    "gru_model = Model(inputs=in_layer, outputs=gru_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_fake = np.random.randint(0, 20000, size=(10, 30))\n",
    "print(x_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_output, gru_state = gru_model(K.tf.convert_to_tensor(x_fake))\n",
    "print(gru_output.shape, type(gru_output))\n",
    "print(gru_state.shape, type(gru_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer = BahdanauAttention(units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_results, att_weights = att_layer(gru_state, gru_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_result, att_weights = att_layer(sample_hidden, sample_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(size=(4, 4))\n",
    "b = np.random.normal(size=(4, 4))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x, y, alpha=0.2):\n",
    "    result = x + (alpha * y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(a, b, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "bpe_tok_path = '/data/users/kyle.shaffer/dialog_data/polar_movie_combined_bpe.tok'\n",
    "\n",
    "bpe_tok = tfds.features.text.SubwordTextEncoder.load_from_file(bpe_tok_path)\n",
    "print(len(token_to_index))\n",
    "print('BPE vocab size:', bpe_tok.vocab_size + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_cakechat_data_with_tok(data_path):\n",
    "    tok_lines = []\n",
    "    # end_id = tokenizer.vocab_size + 1\n",
    "    with open(data_path, mode='r') as infile:\n",
    "        for ix, line in enumerate(infile):\n",
    "            sys.stdout.write('\\r Loading line {}...'.format(ix))\n",
    "            json_line = json.loads(line.strip())\n",
    "            for utt in json_line:\n",
    "                text = utt['text'].strip()\n",
    "                tok_lines.append(text)\n",
    "\n",
    "    return tok_lines\n",
    "\n",
    "train_path = '/data/users/kyle.shaffer/dialog_data/cornell_movie/cakechat_model/corpora_processed/train_no_tok.txt'\n",
    "valid_path = '/data/users/kyle.shaffer/dialog_data/cornell_movie/cakechat_model/corpora_processed/valid_no_tok.txt'\n",
    "train_lines = load_cakechat_data_with_tok(train_path)\n",
    "valid_lines = load_cakechat_data_with_tok(valid_path)\n",
    "\n",
    "all_lines = train_lines + valid_lines\n",
    "\n",
    "bpe = tfds.features.text.SubwordTextEncoder.build_from_corpus(all_lines, target_vocab_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.decode(bpe.encode(\"This is definitely a sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.save_to_file('/data/users/kyle.shaffer/dialog_data/movie_bpe.tok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting Manual Loss Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kyle.shaffer/dialog_model_experiments/src/lm_exp')\n",
    "\n",
    "from inference_models import *\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 45\n",
    "\n",
    "model_dir = '/data/users/kyle.shaffer/chat_models'\n",
    "# Hack code for loading necessary data for 3rd party functions...\n",
    "vocab_path = '/data/users/kyle.shaffer/dialog_data/cornell_movie/cakechat_model/tokens_index/t_idx_processed_dialogs.json'\n",
    "conditions_path = '/data/users/kyle.shaffer/dialog_data/cornell_movie/cakechat_model/conditions_index/conditions_index.json'\n",
    "\n",
    "with open(vocab_path, mode='r') as infile:\n",
    "    token_to_index = json.load(infile)\n",
    "    index_to_token = {int(v): k for k, v in token_to_index.items()}\n",
    "\n",
    "with open(conditions_path, mode='r') as infile:\n",
    "    index_to_condition = json.load(infile)\n",
    "    index_to_condition = {int(k): v for k, v in index_to_condition.items()}\n",
    "    print(index_to_condition)\n",
    "\n",
    "condition_to_index = {v: k for k, v in index_to_condition.items()}\n",
    "\n",
    "valid_name = 'valid_no_tok'\n",
    "valid_data = load_conditioned_dataset(valid_name, token_to_index, condition_to_index, use_gpt_tok=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2s_path = os.path.join(model_dir, 'hierarch_cakechat_50_4.00.h5')\n",
    "s2s_path = os.path.join(model_dir, 'hierarch_cakechat_12_4.08.h5')\n",
    "lm_path = os.path.join(model_dir, 'movie_lm_07_4.13.h5')\n",
    "\n",
    "fuse_model = FuseModel(s2s_path, lm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = fuse_model._get_batch_generator(input_data=(valid_data.x, valid_data.y), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(datagen)\n",
    "# print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = np.argmax(fuse_model.s2s_model.predict(x), axis=-1)\n",
    "print(y_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tok.encoder['_pad_'] = 0\n",
    "gpt_tok.encoder['<unk>'] = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = gpt_tok.tokenize(\"I think you're totally right.\")\n",
    "print(toks)\n",
    "toks.insert(0, '_start_')\n",
    "toks.append('_delimiter_')\n",
    "print(toks)\n",
    "print(gpt_tok.convert_tokens_to_ids(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(datagen)\n",
    "s2s_logits = fuse_model.s2s_model.predict_on_batch(x)\n",
    "print(type(s2s_logits))\n",
    "print(\"Logits shape:\", s2s_logits.shape)\n",
    "\n",
    "loss_ = K.sparse_categorical_crossentropy(K.variable(y), K.variable(s2s_logits), from_logits=True)\n",
    "print(type(loss_))\n",
    "print(\"Loss shape:\", loss_.shape)\n",
    "loss_reduce = K.eval(K.tf.reduce_mean(loss_, axis=1))\n",
    "print(\"Loss reduce type:\", type(loss_reduce))\n",
    "print(\"Loss reduce shape:\", loss_reduce.shape)\n",
    "print(\"Min:\", loss_reduce.min())\n",
    "print(\"Max:\", loss_reduce.max())\n",
    "print(\"Mean:\", loss_reduce.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_loss = fuse_model.s2s_model.test_on_batch(x, y)\n",
    "print('Loss from Keras:', keras_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[1].shape)\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = K.sparse_categorical_crossentropy(K.variable(y[:, :5]), K.variable(s2s_logits[:, :5, :]), from_logits=True)\n",
    "loss = K.eval(loss_)\n",
    "print(loss)\n",
    "np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = K.eval(K.sparse_categorical_crossentropy(K.variable(y), K.variable(s2s_logits), from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasked_loss = loss_[:, :5]\n",
    "unmasked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(unmasked_loss.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(s2s_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_logits[:, :4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for manual computation of S2S loss\n",
    "# Manual score: 3.3555065393447876\n",
    "# Keras score: 2.938905715942383\n",
    "\n",
    "def masked_categorical_crossentropy(y_true, y_pred, mask_value=0):\n",
    "    # find out which timesteps in `y_true` are not the padding character '#'\n",
    "    mask = K.all(K.equal(y_true, mask_value), axis=-1)\n",
    "    mask = 1 - K.cast(mask, K.floatx())\n",
    "\n",
    "    # multiply categorical_crossentropy with the mask\n",
    "    loss = K.categorical_crossentropy(y_true, y_pred) * mask\n",
    "\n",
    "    # take average w.r.t. the number of unmasked entries\n",
    "    return K.sum(loss) / K.sum(mask)\n",
    "\n",
    "def test_manual_loss(fuse_model, use_keras=False, batch_size=1, steps=10):\n",
    "    datagen = fuse_model._get_batch_generator(input_data=(valid_data.x, valid_data.y), batch_size=batch_size)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(steps):\n",
    "        x, y = next(datagen)\n",
    "        if use_keras:\n",
    "            step_loss = fuse_model.s2s_model.test_on_batch(x, y)\n",
    "            print('Step loss:', step_loss)\n",
    "            # total_loss += fuse_model.s2s_model.test_on_batch(x, y)\n",
    "            total_loss += step_loss\n",
    "        else:\n",
    "            logits = fuse_model.s2s_model.predict_on_batch(x)\n",
    "            # loss = K.eval(K.sparse_categorical_crossentropy(K.variable(y), K.variable(logits), from_logits=True))\n",
    "            \n",
    "            # Get mask here\n",
    "            mask = K.all(K.equal(K.variable(y), 0), axis=-1)\n",
    "            mask = 1 - K.cast(mask, K.floatx())\n",
    "            losses = K.sparse_categorical_crossentropy(K.variable(y), K.variable(logits), from_logits=True)\n",
    "            losses = losses * mask\n",
    "            \n",
    "            print(\"Loss shape:\", losses.shape)\n",
    "            loss = K.sum(losses) / K.sum(mask)\n",
    "            step_loss = K.eval(loss)\n",
    "            print('Step loss:', step_loss)\n",
    "            total_loss += K.eval(loss)\n",
    "            \n",
    "            \n",
    "            # batch_loss = 0\n",
    "\n",
    "            # lengths = []\n",
    "            # for ix in range(y.shape[0]):\n",
    "            #     y_i = y[ix]\n",
    "            #     lengths.append(len(y_i[y_i != 0]))\n",
    "            \n",
    "            # print('Lengths:', lengths)\n",
    "                \n",
    "            # loss_mask = K.tf.sequence_mask(lengths, K.tf.to_int32(y.shape[1]))\n",
    "            # print('Loss mask shape:', loss_mask.shape)\n",
    "            # losses = loss * K.tf.to_float(loss_mask)\n",
    "            # np_losses = K.eval(losses)\n",
    "            # mean_loss = 0\n",
    "            # for i in range(np_losses.shape[0]):\n",
    "            #     mean_loss += np.mean(np_losses[i].squeeze())\n",
    "            # total_loss += mean_loss\n",
    "\n",
    "    return total_loss / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_manual_loss(fuse_model, use_keras=True, batch_size=10, steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_manual_loss(fuse_model, use_keras=False, batch_size=10, steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for manual computation of LM loss\n",
    "\n",
    "datagen = fuse_model._get_batch_generator(input_data=(valid_data.x, valid_data.y), batch_size=1)\n",
    "\n",
    "total_loss = 0\n",
    "steps = 1\n",
    "\n",
    "for i in range(steps):\n",
    "    x, y = next(datagen)\n",
    "    x_in = x[1].copy()\n",
    "    x_in[x_in == 40479] = 0\n",
    "    logits = fuse_model.lm_model.predict_on_batch(x_in)\n",
    "    loss = K.eval(K.sparse_categorical_crossentropy(K.variable(y.squeeze()), K.variable(logits), from_logits=True))\n",
    "    \n",
    "    row_c = 0\n",
    "    batch_loss = 0\n",
    "    for row in loss:\n",
    "        sample_loss = np.mean(row.squeeze())\n",
    "        batch_loss += sample_loss\n",
    "        row_c += 1\n",
    "\n",
    "    total_loss += (batch_loss / row_c)\n",
    "    \n",
    "total_loss / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape, y.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = fuse_model._get_batch_generator(input_data=(valid_data.x, valid_data.y), batch_size=1)\n",
    "\n",
    "total_loss = 0\n",
    "steps = 1\n",
    "\n",
    "for i in range(steps):\n",
    "    x, y = next(datagen)\n",
    "    x_in = x[1].copy()\n",
    "    x_in[x_in == 40479] = 0\n",
    "    \n",
    "    batch_loss = fuse_model.lm_model.test_on_batch(x_in, y)\n",
    "    total_loss += batch_loss\n",
    "    \n",
    "total_loss / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_in.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(logits, axis=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_in.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to build separate inference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = fuse_model.lm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s = fuse_model.s2s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fuse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lm_output = lm(s2s.inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_weight_layer = Lambda(lambda x: 0.1 * x)(new_lm_output)\n",
    "add_logits_layer = Add()([s2s.output, lm_weight_layer])\n",
    "inf_graph = Model(inputs=s2s.inputs, outputs=add_logits_layer)\n",
    "inf_graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss(y_true, y_logits):\n",
    "    return K.sparse_categorical_crossentropy(y_true, y_logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_graph.compile(loss=sparse_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(datagen)\n",
    "print(len(x), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s.test_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.test_on_batch(x[1], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_graph.test_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_out = s2s.predict_on_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_out = inf_graph.predict_on_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_tok_ids = np.argmax(comb_out, axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tok.decode(comb_tok_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_tok_ids = np.argmax(s2s_out, axis=-1)[0]\n",
    "gpt_tok.decode(s2s_tok_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    print(np.round(i, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
